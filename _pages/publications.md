---
layout: page
permalink: /publications/
title: research
description: In reversed chronological order.
nav: true
nav_order: 2
---

<span style="font-size: 16px; font-weight: bold;">
  <a href="https://arxiv.org/abs/2506.11440" target="_blank">AbsenceBench: Language Models Can't Tell What's Missing</a>
</span>  
Harvey Yiyun Fu, ***Aryan Shrivastava***, Jared Moore, Peter West, Chenhao Tan, Ari Holtzman
*Under Review*, 2025

<span style="font-size: 16px; font-weight: bold;">
  <a href="https://arxiv.org/abs/2504.10359" target="_blank">DICE: A Framework for Dimensional and Contextual Evaluation of Language Models</a>
</span>  
***Aryan Shrivastava*** and Paula Akemi Aoyagui  
*CHI 2025 Human-Centered Evaluation and Auditing of Language Models (HEAL) Workshop*, 2025

<span style="font-size: 16px; font-weight: bold;">
  <a href="https://www.arxiv.org/abs/2502.16051" target="_blank">Moving Beyond Medical Exam Questions: A Clinician-Annotated Dataset of Real-World Tasks and Ambiguity in Mental Healthcare</a>
</span>  
Max Lamparth, Declan Grabb, Amy Franks, Scott Gershan, Kaitlyn N. Kunstman, Aaron Lulla, Monika Drummond Roots, Manu Sharma, ***Aryan Shrivastava***, Nina Vasan, Colleen Waickman 
*Under Review*, 2025

<span style="font-size: 16px; font-weight: bold;">
  <a href="https://arxiv.org/abs/2410.13204" target="_blank">Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations</a>
</span>  
***Aryan Shrivastava***, Jessica Hullman, Max Lamparth  
*NeurIPS 2024 Socially Responsible Language Modelling Research (SoLaR) Workshop; MILA 2024 Harms and Risks of AI in Military Workshop*, 2024
